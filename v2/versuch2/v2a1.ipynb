{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fun_true** berechnet die Y-Werte der Funktion 2 -x + 3x^2 zu einem gegebenen Input-Vektor X, **generateDataSet** erzeugt zufällige Test-Daten (X,T) im X-Bereich xmin bis xmax. Die zugehörigen Funktionswerte T, werden (von der wahren Funktion ausgehend) mit um sd_noise normalverteilten Noise versehen. **getDataError** berechnet die Summe der Fehlerquadrate (Least Squares Error), den es zu minimieren gilt. **phi_polynomial** berechnet für einen Wert x den entsprechenden \"Polynom-Vektor\" 1 x x^2 x^3 ... vom gegebenen Grad \"deg\" (default=1). Diese Funktion wird benötigt um hinterher die Merkmalsvektoren zu erstellen, die die Design-Matrix ergeben.\n",
    "- Die Daten sind von der Funktion 2 - x + 3x^2 gesampelt (zzgl. Noise)\n",
    "- Die **Basis-Funktionen** sind phi(0)=1, phi(1)=x^1 ..., phi(deg)=x^deg (Annahme: polynomielle Basisfunktionen => Basisfunktionen müssen nicht zwangsläufig polynomiell sein). Die 0-te Basis-Funktion wird auch \"Bias\" genannt (Verschieben der Kurve um entsprechenden Gewichtswert w0).\n",
    "- **lambda** ist der Regularisierungs-Koeffizient, der die relative Gewichtung zwischen der eigentlichen (Daten-)Fehler-Funktion (z.B. least-squares) und dem sogenannten Gewichts-Fehler angibt. Mit dem Gewichts-Fehler versucht man Overfitting zu vermeiden, indem große Gewichte bestraft werden. Große (absolute) Gewichtskomponenten deuten nämlich auf Overfitting hin.\n",
    "- **X,T** sind die Daten für das spätere Training, **X_test,T_test** dienen dann dem Testen des Modells. Erzeugt werden die Daten aber gleich (mittels Funktion generateDataSet)\n",
    "- **grüne Kreuze** = Lern-Daten (\"wahre\" Funktion + Noise), **grüne Punkte** = Test-Daten (\"wahre\" Funktion + Noise), **grüne Kurve** = \"wahre\" Funktion 2 -x + 3x^2, **rote Kurve** = Prognose-Kurve (Ergebnis der least squares Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= [[ 2.71320643]\n",
      " [-4.79248051]\n",
      " [ 1.33648235]\n",
      " [ 2.48803883]\n",
      " [-0.01492988]\n",
      " [-2.75203354]\n",
      " [-3.01937135]\n",
      " [ 2.60530712]\n",
      " [-3.30889163]\n",
      " [-4.11660186]] T= [[24.02637686]\n",
      " [76.78157398]\n",
      " [ 6.06498717]\n",
      " [16.33697066]\n",
      " [ 6.34586048]\n",
      " [39.50347318]\n",
      " [22.71852474]\n",
      " [30.04030926]\n",
      " [40.44148448]\n",
      " [61.40721056]]\n",
      "PHI= [[ 1.00000000e+00  2.71320643e+00  7.36148915e+00  1.99732397e+01\n",
      "   5.41915225e+01  1.47032787e+02]\n",
      " [ 1.00000000e+00 -4.79248051e+00  2.29678694e+01 -1.10073066e+02\n",
      "   5.27523025e+02 -2.52814381e+03]\n",
      " [ 1.00000000e+00  1.33648235e+00  1.78618507e+00  2.38720482e+00\n",
      "   3.19045710e+00  4.26398961e+00]\n",
      " [ 1.00000000e+00  2.48803883e+00  6.19033720e+00  1.54017993e+01\n",
      "   3.83202746e+01  9.53423310e+01]\n",
      " [ 1.00000000e+00 -1.49298770e-02  2.22901226e-04 -3.32788789e-06\n",
      "   4.96849568e-08 -7.41790292e-10]\n",
      " [ 1.00000000e+00 -2.75203354e+00  7.57368863e+00 -2.08430452e+01\n",
      "   5.73607595e+01 -1.57858734e+02]\n",
      " [ 1.00000000e+00 -3.01937135e+00  9.11660336e+00 -2.75264110e+01\n",
      "   8.31124569e+01 -2.50947371e+02]\n",
      " [ 1.00000000e+00  2.60530712e+00  6.78762520e+00  1.76838483e+01\n",
      "   4.60718559e+01  1.20031334e+02]\n",
      " [ 1.00000000e+00 -3.30889163e+00  1.09487638e+01 -3.62282731e+01\n",
      "   1.19875430e+02 -3.96654807e+02]\n",
      " [ 1.00000000e+00 -4.11660186e+00  1.69464109e+01 -6.97616264e+01\n",
      "   2.87180841e+02 -1.18220918e+03]]\n",
      "W_LSR= [[ 7.06500519]\n",
      " [-3.86916089]\n",
      " [ 1.16066097]\n",
      " [ 0.27523414]\n",
      " [ 0.23060499]\n",
      " [ 0.02613605]]\n",
      "Y_test= [[ 5.65809158]\n",
      " [45.63529912]\n",
      " [13.77669052]\n",
      " [ 7.83896266]\n",
      " [ 9.67876039]\n",
      " [10.08485107]\n",
      " [ 5.07045944]\n",
      " [ 6.57739393]\n",
      " [ 6.18850946]\n",
      " [ 4.89231264]]\n",
      "T_test= [[ 3.10905545]\n",
      " [57.97094574]\n",
      " [ 5.36688144]\n",
      " [15.48746047]\n",
      " [ 0.92351025]\n",
      " [-1.52698415]\n",
      " [ 6.31013154]\n",
      " [-2.84101855]\n",
      " [20.36655269]\n",
      " [ 6.00240429]]\n",
      "training data error =  151.66995610334058\n",
      "test data error =  395.93589328555686\n",
      "W_LSR= [[ 7.06500519]\n",
      " [-3.86916089]\n",
      " [ 1.16066097]\n",
      " [ 0.27523414]\n",
      " [ 0.23060499]\n",
      " [ 0.02613605]]\n",
      "mean weight =  2.104467039776552\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# V2A1_LinearRegression.py \n",
    "# Programmgeruest zu Versuch 2, Aufgabe 1\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fun_true(X):                              # compute 1-dim. parable function; X must be Nx1 data matrix\n",
    "    w2,w1,w0 = 3.0,-1.0,2.0                   # true parameters of parable y(x)=w0+w1*x+w2*x*x\n",
    "    return w0+w1*X+w2*np.multiply(X,X)        # return function values (same size as X)\n",
    "\n",
    "def generateDataSet(N,xmin,xmax,sd_noise):    # generate data matrix X and target values T\n",
    "    X=xmin+np.random.rand(N,1)*(xmax-xmin)    # get random x values uniformly in [xmin;xmax)\n",
    "    T=fun_true(X);                            # target values without noise\n",
    "    if(sd_noise>0):\n",
    "        T=T+np.random.normal(0,sd_noise,X.shape) # add noise \n",
    "    return X,T\n",
    "\n",
    "def getDataError(Y,T):                        # compute data error (least squares) between prediction Y and true target values T\n",
    "    D=np.multiply(Y-T,Y-T);                   # squared differences between Y and T\n",
    "    return 0.5*sum(sum(D));                   # return least-squares data error function E_D\n",
    "\n",
    "def phi_polynomial(x,deg=1):                            # compute polynomial basis function vector phi(x) for data x \n",
    "    assert(np.shape(x)==(1,)), \"currently only 1dim data supported\"\n",
    "    return np.array([x[0]**i for i in range(deg+1)]).T; # returns feature vector phi(x)=[1 x x**2 x**3 ... x**deg]\n",
    "\n",
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=5                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"Y_test=\",Y_test)\n",
    "print(\"T_test=\",T_test)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))\n",
    "\n",
    "# (IV) plot data\n",
    "ymin,ymax = -50.0,150.0                     # interval of y data\n",
    "x_=np.arange(xmin,xmax,0.01)                # densely sampled x values\n",
    "Y_LSR = np.array([np.dot(W_LSR.T,np.array([phi_polynomial([x],deg)]).T)[0] for x in x_]);   # least squares prediction\n",
    "Y_true = fun_true(x_).flat\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X.flat,T.flat,c='g',marker='x',s=100)             # plot learning data points (green x)\n",
    "ax.scatter(X_test.flat,T_test.flat,c='g',marker='.',s=100)   # plot test data points (green .)\n",
    "ax.plot(x_,Y_LSR.flat, c='r')         # plot LSR regression curve (red)\n",
    "ax.plot(x_,Y_true, c='g')             # plot true function curve (green)\n",
    "ax.set_xlabel('x')                    # label on x-axis\n",
    "ax.set_ylabel('y')                    # label on y-axis\n",
    "ax.grid()                             # draw a grid\n",
    "plt.ylim((ymin,ymax))                 # set y-limits\n",
    "plt.show()                            # show plot on screen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gewichte: w0=7.065, w1=-3.869, w2=1.161, w3=0.275, w4=0.231, w5=0.026, Lern-Datenfehler 151.670, Test-Datenfehler 396.936. Der Test-Datenfehler ist größer da sich die Gewichte ja entsprechend den Trainings-/Lern-Daten anpassen (Overfitting) und wir diesem Effekt mit lambda=0 noch nicht entgegenwirken (keine Regularisierung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LSR= [[27.46134277]\n",
      " [-5.53569875]]\n",
      "training data error =  1109.2710261079376\n",
      "test data error =  2371.9893767560065\n",
      "W_LSR= [[27.46134277]\n",
      " [-5.53569875]]\n",
      "mean weight =  16.498520760714317\n"
     ]
    }
   ],
   "source": [
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=1                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LSR= [[ 4.63337294]\n",
      " [-0.75955474]\n",
      " [ 3.01744922]]\n",
      "training data error =  164.25156650010845\n",
      "test data error =  215.7704033395336\n",
      "W_LSR= [[ 4.63337294]\n",
      " [-0.75955474]\n",
      " [ 3.01744922]]\n",
      "mean weight =  2.8034589676194686\n"
     ]
    }
   ],
   "source": [
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=2                                                           # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LSR= [[ 4.12430351]\n",
      " [-1.04668517]\n",
      " [ 3.13260883]\n",
      " [ 0.03723243]]\n",
      "training data error =  163.50151393233\n",
      "test data error =  209.67536254495204\n",
      "W_LSR= [[ 4.12430351]\n",
      " [-1.04668517]\n",
      " [ 3.13260883]\n",
      " [ 0.03723243]]\n",
      "mean weight =  2.0852074847586572\n"
     ]
    }
   ],
   "source": [
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=3                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LSR= [[ 6.13209654]\n",
      " [-4.23683628]\n",
      " [ 2.28662209]\n",
      " [ 0.47537592]\n",
      " [ 0.0978666 ]]\n",
      "training data error =  154.65214472845722\n",
      "test data error =  374.2566549998293\n",
      "W_LSR= [[ 6.13209654]\n",
      " [-4.23683628]\n",
      " [ 2.28662209]\n",
      " [ 0.47537592]\n",
      " [ 0.0978666 ]]\n",
      "mean weight =  2.645759485825523\n"
     ]
    }
   ],
   "source": [
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=4                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LSR= [[ 7.06500519]\n",
      " [-3.86916089]\n",
      " [ 1.16066097]\n",
      " [ 0.27523414]\n",
      " [ 0.23060499]\n",
      " [ 0.02613605]]\n",
      "training data error =  151.66995610334064\n",
      "test data error =  395.9358932860801\n",
      "W_LSR= [[ 7.06500519]\n",
      " [-3.86916089]\n",
      " [ 1.16066097]\n",
      " [ 0.27523414]\n",
      " [ 0.23060499]\n",
      " [ 0.02613605]]\n",
      "mean weight =  2.1044670397799394\n"
     ]
    }
   ],
   "source": [
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=5                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LSR= [[  6.30511752]\n",
      " [-18.32603334]\n",
      " [ 12.20577398]\n",
      " [  4.42482395]\n",
      " [ -2.3225259 ]\n",
      " [ -0.50636585]\n",
      " [  0.15183148]\n",
      " [  0.02936846]]\n",
      "training data error =  119.13824260532076\n",
      "test data error =  1227.2433837505214\n",
      "W_LSR= [[  6.30511752]\n",
      " [-18.32603334]\n",
      " [ 12.20577398]\n",
      " [  4.42482395]\n",
      " [ -2.3225259 ]\n",
      " [ -0.50636585]\n",
      " [  0.15183148]\n",
      " [  0.02936846]]\n",
      "mean weight =  5.533980061026324\n"
     ]
    }
   ],
   "source": [
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=7                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LSR= [[ 5.23764685e+00]\n",
      " [-7.18981005e+01]\n",
      " [ 1.55792089e+02]\n",
      " [-1.63213623e+01]\n",
      " [-6.87193097e+01]\n",
      " [ 4.34836797e+00]\n",
      " [ 1.08937206e+01]\n",
      " [ 4.29951920e-01]\n",
      " [-5.92362198e-01]\n",
      " [-7.45439491e-02]]\n",
      "training data error =  6.121379950776229e-11\n",
      "test data error =  37529.46503637709\n",
      "W_LSR= [[ 5.23764685e+00]\n",
      " [-7.18981005e+01]\n",
      " [ 1.55792089e+02]\n",
      " [-1.63213623e+01]\n",
      " [-6.87193097e+01]\n",
      " [ 4.34836797e+00]\n",
      " [ 1.08937206e+01]\n",
      " [ 4.29951920e-01]\n",
      " [-5.92362198e-01]\n",
      " [-7.45439491e-02]]\n",
      "mean weight =  33.4307454757652\n"
     ]
    }
   ],
   "source": [
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bei **niedrigen Polynomgraden** ist das Modell zu **unflexibel** was zu größeren Abweichungen bei Trainings- und Test-Daten führt. Bei **höheren Polynomgraden** ist das Modell **flexibler** und die Abweichungen auf den Trainings-Daten werden damit immer geringer. Dafür zeigt sich bei höheren Polynomgraden umso mehr der Effekt des **Overfitting** sodass die Test-Daten nicht gut reproduziert werden können (hoher Test-Daten-Fehler).\n",
    "- Der Effekt des Overfitting zeigt sich auch beim **Wert des mittleren Gewichts**. Bei höheren Polynomgraden werden sehr große Werte erzeugt. Um in Summe trotzdem möglichst nah an die Zielwerte T zu kommen, müssen die hohen Werte durch stark gewichtete andere Basisfunktionen aufgehoben werden (die Gewichte müssen also zusätzlich auch teils positiv, teils negativ sein um den Aufhebungs-Effekt zu erzielen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ermittlung mittlerer Lern-/Test-Datenfehler für Polynomgrad 9 bei N=10,100,1000,10000 Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  6.121379950776229e-12\n",
      "test data error =  3752.946503637709\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T)/N)\n",
    "print(\"test data error = \", getDataError(Y_test,T_test)/N)\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "#print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  43.33105957908105\n",
      "test data error =  44.07319425722218\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=100                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T)/N)\n",
    "print(\"test data error = \", getDataError(Y_test,T_test)/N)\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "#print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  47.43467339586494\n",
      "test data error =  53.18131707183179\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=1000                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T)/N)\n",
    "print(\"test data error = \", getDataError(Y_test,T_test)/N)\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "#print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  50.40076433890359\n",
      "test data error =  50.42360748661833\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10000                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T)/N)\n",
    "print(\"test data error = \", getDataError(Y_test,T_test)/N)\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "#print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "- **Beobachtung**: bei steigendem N wird der Test-Datenfehler kleiner (Lern-Datenfehler steigt dabei leicht)\n",
    "- **Begründung**: je mehr Daten ich (in einem bestimmten Bereich) habe, desto unwahrscheinlicher/unmöglicher ist es eine (im bestimmten Bereich) stark oszillierende Funktion zu finden (=großes Overfitting) daher helfen mehr Daten dabei, Overfitting zu reduzieren => je mehr Daten ich habe, desto wahrscheinlicher ist es, dass die gefundene Funktion (im Datenbereich) die originale Funktion abbildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LSR= [[ 2.09080823]\n",
      " [-0.99705204]\n",
      " [ 3.03158826]]\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=6000                                        # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=2                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "#print(\"training data error = \", getDataError(Y_train,T)/N)\n",
    "#print(\"test data error = \", getDataError(Y_test,T_test)/N)\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "#print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Durch Ausprobieren (N=10,100,1000,5000,6000) zeigt sich, dass ca. bei N=6000 die Gewichte (2,-1,3) mit einer Abweichung von <10% getroffen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Regularisierung** hilft dabei den **Effekt des Overfitting** bei linearen Regressionen zu **verringern**. Wie bereits oben erwähnt, deuten hohe Gewichte auf Overfitting hin. Der Ansatz der Regularisierung nimmt nun die Summe der Gewichte beziehungsweise die q-Norm des Gewichtsvektors (für q=2 entspricht das der euklidischen Länge des Gewichtsvektors) in die zu minimierende Fehlerfunktion mit auf. Somit werden bei der Minimierung der Fehlerfunktion große Gewichte bestraft und dadurch Overfitting reduziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda = 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  6.121379950776229e-11\n",
      "test data error =  37529.46503637709\n",
      "mean weight =  33.4307454757652\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0                                                           # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda = 0.01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  34.05186042439203\n",
      "test data error =  6364.578341801348\n",
      "mean weight =  14.596340243529088\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0.01                                                           # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda = 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  106.92744753585548\n",
      "test data error =  847.6887178422261\n",
      "mean weight =  3.4180536892402813\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=0.1                                                          # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda = 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  134.61567675497696\n",
      "test data error =  368.5967945183438\n",
      "mean weight =  0.9811606165361744\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=1                                                           # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda = 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  158.09431539758128\n",
      "test data error =  272.5295875920798\n",
      "mean weight =  0.42991944508130714\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=10                                                          # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  169.91859679273807\n",
      "test data error =  266.51924091701426\n",
      "mean weight =  0.3145198799935035\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=20                                                          # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda = 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  212.98533792828155\n",
      "test data error =  295.18957735479836\n",
      "mean weight =  0.10356099151824291\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=100                                                          # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda = 1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  245.54595461987873\n",
      "test data error =  333.2755496676857\n",
      "mean weight =  0.03382471662350579\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=1000                                                          # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data error =  260.0201793141446\n",
      "test data error =  355.23951254546256\n",
      "mean weight =  0.02252536129443288\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                          # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "#print(\"X=\",X, \"T=\",T)\n",
    "\n",
    "# (II) generate linear least squares model for regression\n",
    "lmbda=10000                                                          # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "#print(\"PHI=\", PHI)\n",
    "W_LSR = np.dot(np.dot(np.linalg.inv(np.dot(PHI.T,PHI)+lmbda*np.eye(M)),PHI.T),T)\n",
    "#W_LSR = np.linalg.solve(PHI.T.dot(PHI)+lmbda*np.identity(PHI.shape[1]),PHI.T.dot(T))  # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "\n",
    "# (III) make predictions for training and test data\n",
    "Y_train = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X])  # REPLACE THIS BY PROGNOSIS FOR TRAINING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([np.dot(W_LSR.T,np.array([phi_polynomial(x,deg)]).T)[0] for x in X_test])   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "print(\"training data error = \", getDataError(Y_train,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "#print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wenn **lambda zu klein** gewählt wird, bekommt man das Overfitting-Problem nicht in den Griff.\n",
    "- wenn **lambda zu groß** gewählt wird, legt man in der Fehlerfunktion zu viel Gewicht auf die Reduzierung der Gewichte und zu wenig Gewicht die Abweichungen mittels least squares zu minimieren sodass man zwar niedrige Gewichte erhält aber die Daten nicht gut trifft.\n",
    "- unter den getesteten Lambdas erhält man mit **lambda=20** den kleinsten Generalisierungsfehler auf den Test-Daten\n",
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
